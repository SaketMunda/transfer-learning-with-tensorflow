{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD1humXqkW4yI/1xepR0xy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/transfer-learning-with-tensorflow/blob/master/transfer_learning_with_tensorflow_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow - Part 1 : Feature Extraction\n",
        "\n",
        "\n",
        "If you've been thinking, \"surely someone else has spent the time crafting the right model for the job...\" then you're in luck.\n",
        "\n",
        "For many of the problems, you'll want to use deep learning for, chances are, a working model already exists.\n",
        "\n",
        "And the good news is, you can access many of them on TensorFlow Hub.\n",
        "\n",
        "[TensorFlow Hub](https://tfhub.dev/) is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.\n",
        "\n",
        "For this notebook we will experiment the Food Vision problem that we did in [this repo](https://github.com/SaketMunda/cnn-computer-vision-introduction) but with less data, to be specific only 10% of data for training set.\n",
        "\n",
        "Why ? **Transfer leanring often allows you to get great results with less data.**\n",
        "\n",
        "## Problem Definition\n",
        "\n",
        "We're working towards building, taking a pre-trained model and adding our own custom layers on top, extracting all of the underlying patterns learned on another dataset of our own images."
      ],
      "metadata": {
        "id": "HVt0lPEjIicm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and becoming one with the data"
      ],
      "metadata": {
        "id": "sUlKKdSLLAZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# unzip the downloaded data\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjcnvRz-LENA",
        "outputId": "39699a16-bb1f-441e-f630-b1e2483d309d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-08 05:20:34--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.128.128, 74.125.143.128, 173.194.79.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.128.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  32.1MB/s    in 5.4s    \n",
            "\n",
            "2022-12-08 05:20:40 (29.5 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images we have in each folder ?\n",
        "\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk('10_food_classes_10_percent'):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAqHWvUCLaVp",
        "outputId": "7363f96b-2676-4281-e73c-b35d9e3fab87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how each of the training directories now has 75 images rather than 750 images. This is the key to demonstrating how well transfer learning can perform with less labelled images.\n",
        "\n",
        "The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data."
      ],
      "metadata": {
        "id": "j7fMMxArL19B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "Now we've downloaded the data, let's use the `ImageDateGenerator` class along with the `flow_from_directory` method to load in our images."
      ],
      "metadata": {
        "id": "agsNsTCbMNbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "# Initiating ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMG_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "print(\"Test images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMG_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNC5LCKZMbXV",
        "outputId": "df2da674-686d-48be-91f4-90c5cc7cfe01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Test images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (thing to run whilst training our model)\n",
        "\n",
        "Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model experiments.\n",
        "\n",
        "And that concept is **callbacks**.\n",
        "\n",
        "[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "\n",
        "- [Experiment tracking with TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - log the performance of multiple models and then view and compare these models in a visual way on [TensorBoard](https://www.tensorflow.org/tensorboard)(a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n",
        "- [Model Checkpoints](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "- [Early Stopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n",
        "\n",
        "\n",
        "The Tensorboard callback can be accessed using `tf.keras.callbacks.TensorBoard()`.\n",
        "\n",
        "It's main functionality is saving a model's training performance metrics to a specified `log_dir`.\n",
        "\n",
        "To track our modelling experiments using TensorBoard, let's create a function which creates a TensorBoard callback for us.\n",
        "\n",
        "> **Note**: We create a function for creating a TensorBoard callback because as we'll see later on, each model needs its own TensorBoard callback instance(so the function will create a new one each time it's run).\n"
      ],
      "metadata": {
        "id": "kT4_1hd8Nfw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CReate tensorboard callback (functionized because need to create a new one for each model)\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(\n",
        "      log_dir = log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "ALRSx1QNPoZx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oP_gyQaqQV9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}