{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO5YpYdpUVXRCH1MT6yvpnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/transfer-learning-with-tensorflow/blob/master/fine_tuning_transfer_learning_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow : Fine Tuning\n",
        "\n",
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food vision project (using only 10% of original dataset) than building our own model from scratch.\n",
        "\n",
        "Now, we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "*Feature extraction transfer learning vs. fine-tuning transfer learning. The main difference between the two is that in fine-tuning, more layers of the pre-trained model get unfrozen and tuned on custom data. This fine-tuning usually takes more data than feature extraction to be effective.*"
      ],
      "metadata": {
        "id": "STYzc-8ZGhqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ’¡ **This time we will use the helper functions to speed up our steps in learning**"
      ],
      "metadata": {
        "id": "YHIrqFznIW1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Helper functions"
      ],
      "metadata": {
        "id": "eE_H8bZLIq8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from Github\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Nsxn6zI1lG",
        "outputId": "54b7ff20-020d-4ad2-aceb-6562955b24f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-16 05:53:59--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1937 (1.9K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-16 05:53:59 (31.9 MB/s) - â€˜helper_functions.pyâ€™ saved [1937/1937]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Food Classes : Working with Less data\n",
        "\n",
        "As in the previous notebook of Transfer Leanring : Feature Extraction, we got good results from less data (10%) of the training data using transfer learning from TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use in-built pretrained models within the `tf.keras.applications` module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, `image_dataset_from_directory()` which is a part of `tf.keras.preprocessing` module.\n",
        "\n",
        "Finally we'll be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The functional API is a more flexible way to create models than the `tf.keras.Sequential`\n",
        "\n",
        "Let's start by downloading the data"
      ],
      "metadata": {
        "id": "9Z7N0tt_JC2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data('10_food_classes_10_percent.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5ovR3QKRHo",
        "outputId": "5bce735f-f7e8-4f99-f00a-7bd3abcbb46d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-16 05:54:05--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 108.177.98.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   176MB/s    in 0.9s    \n",
            "\n",
            "2022-12-16 05:54:06 (176 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through the directory and list number of files\n",
        "walk_through_dir('10_food_classes_10_percent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3SlAZCrKbAE",
        "outputId": "b61c2d1b-a324-4206-e956-1ec56655eb6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 files in '10_food_classes_10_percent'\n",
            "There are 10 directories and 0 files in '10_food_classes_10_percent/train'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/chicken_wings'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/steak'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/ice_cream'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/pizza'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/hamburger'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/fried_rice'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/grilled_salmon'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/ramen'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/chicken_curry'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/sushi'\n",
            "There are 10 directories and 0 files in '10_food_classes_10_percent/test'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/steak'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/ice_cream'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/pizza'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/hamburger'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/fried_rice'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/ramen'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/sushi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same number of files and classes we used in previous notebook."
      ],
      "metadata": {
        "id": "Qz_b4_CSKotm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training and testing directory\n",
        "train_dir = '10_food_classes_10_percent/train/'\n",
        "test_dir = '10_food_classes_10_percent/test/'"
      ],
      "metadata": {
        "id": "pKTTG2hDLrBi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some image data, we need a way of loading it into a Tensorflow compatible format.\n",
        "\n",
        "Previously, we've used the `ImageDataGenerator` class. And while this works well and is still very commonly used, this time we're going to use the `image_dataset_from_directory` function.\n",
        "\n",
        "One of the main benefits of using `tf.keras.preprocessing.image_dataset_from_directory()` rather than `ImageDataGenerator` is that it creates a `tf.data.Dataset` object rather than a generator. The main advantage of this is the `tf.data.Dataset` API is much faster and efficient than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "5W-OTNfVL9wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                  image_size=IMG_SHAPE,\n",
        "                                                  label_mode='categorical',\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                 image_size=IMG_SHAPE,\n",
        "                                                 label_mode='categorical',\n",
        "                                                 batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSN8trhhMway",
        "outputId": "9e73fe37-a851-46a3-8bb8-57df7cf7f4f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful ! Looks like our dataloaders have found the correct number of images for each Dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory` function are:\n",
        "- `directory`\n",
        "- `image_size`\n",
        "- `batch_size`"
      ],
      "metadata": {
        "id": "fxpB4afwNRV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if we check the datatype of the preprocessed dataset\n",
        "train_data_10_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSPzMR7aOHaD",
        "outputId": "47dba9dd-fe0c-4bb4-e26e-889c48c80da7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's Batch Dataset"
      ],
      "metadata": {
        "id": "x3n5eA58ONgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the classes\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEPxjDtmOcEf",
        "outputId": "48ebd66b-0aa4-4e6a-d74e-4681d2d6d2ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or if we wanted to see an example of batch of data, we could use the `take()` method"
      ],
      "metadata": {
        "id": "c05996fLOfDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDp1gSWqOsq3",
        "outputId": "fdb1156f-9692-4f80-fbd4-359d74d53f9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[7.49846954e+01 2.19846935e+01 5.98469353e+00]\n",
            "   [8.14234772e+01 2.84234734e+01 1.24234715e+01]\n",
            "   [7.82040787e+01 2.52040825e+01 7.20408344e+00]\n",
            "   ...\n",
            "   [9.23366776e+01 3.16275311e+01 8.25512695e+00]\n",
            "   [1.01515282e+02 4.05152817e+01 2.15152836e+01]\n",
            "   [9.60258255e+01 3.50258255e+01 1.70258255e+01]]\n",
            "\n",
            "  [[8.78622437e+01 3.11989803e+01 1.65306129e+01]\n",
            "   [9.22653122e+01 3.62653122e+01 2.12653084e+01]\n",
            "   [7.88367386e+01 2.58367367e+01 7.83673620e+00]\n",
            "   ...\n",
            "   [9.30457840e+01 3.10457840e+01 7.61725616e+00]\n",
            "   [9.23725052e+01 3.13725033e+01 1.23725033e+01]\n",
            "   [9.67041702e+01 3.57041740e+01 1.77041721e+01]]\n",
            "\n",
            "  [[9.27244949e+01 3.37244873e+01 1.97244911e+01]\n",
            "   [8.71479568e+01 2.91479568e+01 1.51479568e+01]\n",
            "   [8.82704086e+01 3.29132614e+01 1.56989784e+01]\n",
            "   ...\n",
            "   [9.55917664e+01 3.35917625e+01 1.01632347e+01]\n",
            "   [1.07147827e+02 4.50916939e+01 2.42600937e+01]\n",
            "   [9.37090683e+01 3.22804985e+01 1.42805004e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.29101990e+02 1.29101990e+02 1.19101997e+02]\n",
            "   [1.18882698e+02 1.18882698e+02 1.08882698e+02]\n",
            "   [1.12392868e+02 1.10035660e+02 1.00821396e+02]\n",
            "   ...\n",
            "   [1.04316208e+02 3.84998474e+01 1.53109941e+01]\n",
            "   [1.07285706e+02 4.12857056e+01 1.68571777e+01]\n",
            "   [9.51532440e+01 3.11532440e+01 5.72471619e+00]]\n",
            "\n",
            "  [[1.25831696e+02 1.22831696e+02 1.13831696e+02]\n",
            "   [1.26117500e+02 1.23117500e+02 1.14117500e+02]\n",
            "   [1.17240082e+02 1.13240082e+02 1.04240082e+02]\n",
            "   ...\n",
            "   [9.96834946e+01 3.36988029e+01 9.23966122e+00]\n",
            "   [9.68622208e+01 3.07244415e+01 9.14798737e+00]\n",
            "   [9.79031601e+01 3.09031639e+01 1.39746046e+01]]\n",
            "\n",
            "  [[1.31357498e+02 1.27357491e+02 1.16357491e+02]\n",
            "   [1.45500381e+02 1.41500381e+02 1.30500381e+02]\n",
            "   [1.59005524e+02 1.54362671e+02 1.43576950e+02]\n",
            "   ...\n",
            "   [1.03699028e+02 3.96990280e+01 1.40562363e+01]\n",
            "   [9.60459213e+01 2.90459251e+01 1.02143250e+01]\n",
            "   [1.01285645e+02 3.32856445e+01 2.05407963e+01]]]\n",
            "\n",
            "\n",
            " [[[1.55153061e+02 1.40994904e+02 1.20326530e+02]\n",
            "   [1.67066330e+02 1.47255096e+02 1.23158165e+02]\n",
            "   [1.97867340e+02 1.69581635e+02 1.38510208e+02]\n",
            "   ...\n",
            "   [2.83879261e+01 2.20868416e+01 1.88062210e+01]\n",
            "   [3.79489059e+01 2.82805328e+01 1.91172371e+01]\n",
            "   [2.60967674e+01 1.30406666e+01 1.60705566e+00]]\n",
            "\n",
            "  [[1.58403061e+02 1.43974487e+02 1.18831635e+02]\n",
            "   [1.55535721e+02 1.34811218e+02 1.07596939e+02]\n",
            "   [1.99857147e+02 1.73000000e+02 1.39244904e+02]\n",
            "   ...\n",
            "   [1.85969868e+01 1.39132881e+01 1.01989813e+01]\n",
            "   [3.29185104e+01 2.39848213e+01 1.67092743e+01]\n",
            "   [3.45710106e+01 2.50455322e+01 1.21219654e+01]]\n",
            "\n",
            "  [[1.60545914e+02 1.44683670e+02 1.12770409e+02]\n",
            "   [1.64285721e+02 1.44158157e+02 1.10142860e+02]\n",
            "   [1.47698975e+02 1.21178574e+02 8.42244949e+01]\n",
            "   ...\n",
            "   [1.60664864e+01 1.27092791e+01 9.92354298e+00]\n",
            "   [1.81633224e+01 1.25918674e+01 6.03572083e+00]\n",
            "   [3.35972214e+01 2.63829346e+01 1.71787987e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.43862259e+02 9.38622589e+01 2.32908459e+01]\n",
            "   [1.51642853e+02 1.01642853e+02 3.06734619e+01]\n",
            "   [1.49790863e+02 1.03576561e+02 2.92194443e+01]\n",
            "   ...\n",
            "   [1.12209465e+02 7.80410614e+01 3.14440594e+01]\n",
            "   [9.55408859e+01 5.74439278e+01 9.85714722e+00]\n",
            "   [1.08683395e+02 6.66069107e+01 1.97547417e+01]]\n",
            "\n",
            "  [[1.47714340e+02 9.77143402e+01 2.87143383e+01]\n",
            "   [1.50923477e+02 1.00923470e+02 3.17908497e+01]\n",
            "   [1.52816330e+02 1.05816315e+02 3.38163185e+01]\n",
            "   ...\n",
            "   [1.14990128e+02 7.90207291e+01 2.71941528e+01]\n",
            "   [8.78520737e+01 5.16480141e+01 7.09192753e-01]\n",
            "   [1.03137466e+02 6.59232330e+01 1.40864573e+01]]\n",
            "\n",
            "  [[1.45367355e+02 9.43673630e+01 2.83673611e+01]\n",
            "   [1.51117340e+02 1.00448982e+02 3.34540749e+01]\n",
            "   [1.50204086e+02 1.03204094e+02 3.27755165e+01]\n",
            "   ...\n",
            "   [1.06066727e+02 7.26381989e+01 1.86381989e+01]\n",
            "   [1.02805969e+02 6.97294235e+01 1.67549381e+01]\n",
            "   [9.91019287e+01 6.31019249e+01 1.11019258e+01]]]\n",
            "\n",
            "\n",
            " [[[1.01142860e+02 9.91428604e+01 7.81428604e+01]\n",
            "   [8.62142868e+01 8.52142868e+01 6.52142868e+01]\n",
            "   [6.47142868e+01 6.55000000e+01 5.03571434e+01]\n",
            "   ...\n",
            "   [1.09214264e+02 9.42142639e+01 6.12142639e+01]\n",
            "   [1.08974487e+02 9.39744873e+01 6.09744835e+01]\n",
            "   [1.08000000e+02 9.30000000e+01 6.00000000e+01]]\n",
            "\n",
            "  [[1.03428574e+02 1.01428574e+02 8.04285736e+01]\n",
            "   [8.85000000e+01 8.75000000e+01 6.75000000e+01]\n",
            "   [6.70153046e+01 6.78010178e+01 5.26581650e+01]\n",
            "   ...\n",
            "   [1.10000000e+02 9.50000000e+01 6.20000000e+01]\n",
            "   [1.09000000e+02 9.40000000e+01 6.10000000e+01]\n",
            "   [1.09000000e+02 9.40000000e+01 6.10000000e+01]]\n",
            "\n",
            "  [[1.04280617e+02 1.01637756e+02 7.88520432e+01]\n",
            "   [9.07142868e+01 8.77857132e+01 6.86428604e+01]\n",
            "   [6.89030609e+01 6.75459213e+01 5.27602043e+01]\n",
            "   ...\n",
            "   [1.10000000e+02 9.50000000e+01 6.20000000e+01]\n",
            "   [1.10015312e+02 9.50153122e+01 6.20153084e+01]\n",
            "   [1.11000000e+02 9.60000000e+01 6.30000000e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[3.64279175e+00 2.00000000e+00 2.14263916e-01]\n",
            "   [4.62748718e+00 2.98469543e+00 1.19895935e+00]\n",
            "   [5.64279175e+00 4.00000000e+00 2.21426392e+00]\n",
            "   ...\n",
            "   [6.78111496e+01 3.97652359e+01 3.48316460e+01]\n",
            "   [6.59437408e+01 3.79284973e+01 3.34285278e+01]\n",
            "   [6.57141418e+01 3.84948807e+01 3.37091751e+01]]\n",
            "\n",
            "  [[3.00000000e+00 1.00000000e+00 2.00000000e+00]\n",
            "   [3.00000000e+00 1.00000000e+00 2.00000000e+00]\n",
            "   [3.92855835e+00 1.92855835e+00 2.92855835e+00]\n",
            "   ...\n",
            "   [6.02142029e+01 3.53570862e+01 2.98571167e+01]\n",
            "   [5.55815582e+01 3.29948959e+01 2.68571167e+01]\n",
            "   [5.50764313e+01 3.32857361e+01 2.68826332e+01]]\n",
            "\n",
            "  [[3.12756348e+00 3.12756348e+00 3.12756348e+00]\n",
            "   [3.00000000e+00 3.00000000e+00 3.00000000e+00]\n",
            "   [3.00000000e+00 3.00000000e+00 3.00000000e+00]\n",
            "   ...\n",
            "   [5.60815277e+01 3.39234695e+01 2.72142944e+01]\n",
            "   [5.28826332e+01 3.32857361e+01 2.62857361e+01]\n",
            "   [5.06428223e+01 3.16428223e+01 2.46428223e+01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[3.00000000e+00 5.00000000e+00 2.00000000e+00]\n",
            "   [2.00000000e+00 4.00000000e+00 1.00000000e+00]\n",
            "   [1.21428585e+00 3.21428585e+00 2.14285851e-01]\n",
            "   ...\n",
            "   [7.85705566e-01 5.70917177e+00 1.70917189e+00]\n",
            "   [0.00000000e+00 4.04590702e+00 4.59071621e-02]\n",
            "   [4.13262546e-01 5.28570986e+00 1.28570998e+00]]\n",
            "\n",
            "  [[2.04591823e+00 4.04591799e+00 1.04591823e+00]\n",
            "   [2.00000000e+00 4.00000000e+00 1.00000000e+00]\n",
            "   [1.21428585e+00 3.21428585e+00 2.14285851e-01]\n",
            "   ...\n",
            "   [9.84693289e-01 5.98469353e+00 1.98469329e+00]\n",
            "   [9.28571701e-01 5.92857170e+00 1.92857170e+00]\n",
            "   [3.16835928e+00 8.16835976e+00 4.16835928e+00]]\n",
            "\n",
            "  [[1.78571415e+00 3.78571415e+00 1.21428585e+00]\n",
            "   [1.78571415e+00 3.78571415e+00 7.85714149e-01]\n",
            "   [1.95408154e+00 3.95408154e+00 9.54081595e-01]\n",
            "   ...\n",
            "   [2.59693718e+00 6.95407963e+00 3.07652497e+00]\n",
            "   [2.62755513e+00 6.98469782e+00 2.77041173e+00]\n",
            "   [5.07142448e+00 9.42856693e+00 5.21428108e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[4.45153465e+01 3.60868187e+01 2.53010845e+01]\n",
            "   [4.70613289e+01 3.86634102e+01 2.58623676e+01]\n",
            "   [5.67551918e+01 4.95409050e+01 3.41837616e+01]\n",
            "   ...\n",
            "   [5.03164291e+01 5.09133987e+01 2.36021347e+01]\n",
            "   [4.36276436e+01 4.64133797e+01 2.00561714e+01]\n",
            "   [3.57447739e+01 3.93162460e+01 1.49590378e+01]]\n",
            "\n",
            "  [[2.15305138e+01 1.56682796e+01 7.59690428e+00]\n",
            "   [4.38160439e+01 3.71630058e+01 2.90916061e+01]\n",
            "   [3.96528931e+01 3.56528931e+01 2.47957783e+01]\n",
            "   ...\n",
            "   [4.35150948e+01 4.55865364e+01 2.22294521e+01]\n",
            "   [3.93467293e+01 4.31426697e+01 2.04947453e+01]\n",
            "   [4.51681557e+01 4.98365211e+01 2.70508480e+01]]\n",
            "\n",
            "  [[2.03879395e+01 1.63879395e+01 1.41022949e+01]\n",
            "   [1.54848108e+01 1.15307264e+01 8.43889523e+00]\n",
            "   [1.86836624e+01 1.40356970e+01 9.97448730e+00]\n",
            "   ...\n",
            "   [2.46123466e+01 2.76888885e+01 9.83183289e+00]\n",
            "   [2.52856445e+01 2.92397404e+01 1.29540949e+01]\n",
            "   [2.85667286e+01 3.25667267e+01 1.62810841e+01]]]\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [6.49897842e+01 7.09897842e+01 6.09897804e+01]\n",
            "   [6.39081688e+01 6.99081650e+01 5.99081688e+01]\n",
            "   [6.11734810e+01 6.71734772e+01 5.71734810e+01]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [6.39591866e+01 6.99591827e+01 5.79591866e+01]\n",
            "   [6.59286041e+01 7.19286041e+01 5.99286041e+01]\n",
            "   [6.23826714e+01 6.83826675e+01 5.63826714e+01]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [6.88520050e+01 7.28520050e+01 5.76836472e+01]\n",
            "   [6.56275558e+01 6.96275558e+01 5.42856979e+01]\n",
            "   [6.70102005e+01 7.10102005e+01 5.60153084e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[8.95969849e+01 8.10918732e+01 4.65306969e+01]\n",
            "   [7.87141571e+01 6.87141571e+01 3.34998894e+01]\n",
            "   [9.24233856e+01 8.24233856e+01 4.72091255e+01]\n",
            "   ...\n",
            "   [1.62142334e+01 1.30458546e+01 0.00000000e+00]\n",
            "   [1.58264542e+01 1.34999695e+01 1.98963106e-01]\n",
            "   [1.45713501e+01 1.23570862e+01 7.65237510e-02]]\n",
            "\n",
            "  [[8.67806396e+01 7.77806396e+01 4.67806358e+01]\n",
            "   [8.79999771e+01 7.69999771e+01 4.68673210e+01]\n",
            "   [9.00255127e+01 7.90255127e+01 4.86275597e+01]\n",
            "   ...\n",
            "   [1.27550869e+01 1.08010149e+01 0.00000000e+00]\n",
            "   [1.09948673e+01 1.17959394e+01 0.00000000e+00]\n",
            "   [8.66836834e+00 9.66836834e+00 0.00000000e+00]]\n",
            "\n",
            "  [[9.06069870e+01 8.16069870e+01 5.26069870e+01]\n",
            "   [8.99032364e+01 7.89032364e+01 5.09032326e+01]\n",
            "   [9.21582184e+01 8.11582184e+01 5.31582184e+01]\n",
            "   ...\n",
            "   [1.37908354e+01 1.24337187e+01 0.00000000e+00]\n",
            "   [1.26429443e+01 1.36429443e+01 3.31671268e-01]\n",
            "   [9.78582764e+00 1.17858276e+01 1.27565026e-01]]]\n",
            "\n",
            "\n",
            " [[[2.54357147e+02 2.46357147e+02 2.00739792e+02]\n",
            "   [2.52071426e+02 2.45928574e+02 1.98071426e+02]\n",
            "   [2.50275513e+02 2.44918365e+02 1.92551025e+02]\n",
            "   ...\n",
            "   [2.50637756e+02 2.44637756e+02 2.29352051e+02]\n",
            "   [2.51403076e+02 2.45403076e+02 2.32117355e+02]\n",
            "   [2.52357147e+02 2.46357147e+02 2.34357147e+02]]\n",
            "\n",
            "  [[2.52739792e+02 2.44739792e+02 1.98739792e+02]\n",
            "   [2.49418365e+02 2.43275513e+02 1.95418365e+02]\n",
            "   [2.44714279e+02 2.39357132e+02 1.89112244e+02]\n",
            "   ...\n",
            "   [2.47142853e+02 2.40142853e+02 2.21214279e+02]\n",
            "   [2.49214294e+02 2.42214294e+02 2.24357147e+02]\n",
            "   [2.51096939e+02 2.44025513e+02 2.26382660e+02]]\n",
            "\n",
            "  [[2.50219391e+02 2.42219391e+02 1.96219391e+02]\n",
            "   [2.45984680e+02 2.38913254e+02 1.92913254e+02]\n",
            "   [2.47642853e+02 2.41285706e+02 1.95071426e+02]\n",
            "   ...\n",
            "   [2.46785736e+02 2.39785736e+02 2.13357162e+02]\n",
            "   [2.47857162e+02 2.40071442e+02 2.16428589e+02]\n",
            "   [2.49066360e+02 2.41066360e+02 2.19637787e+02]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[2.46000000e+02 2.19214264e+02 1.01785736e+02]\n",
            "   [2.46198959e+02 2.19413223e+02 1.01984695e+02]\n",
            "   [2.47045914e+02 2.20260178e+02 1.02831650e+02]\n",
            "   ...\n",
            "   [2.49000000e+02 2.24000000e+02 1.67954086e+02]\n",
            "   [2.47056137e+02 2.24255096e+02 1.69658218e+02]\n",
            "   [2.47719345e+02 2.25280655e+02 1.71000000e+02]]\n",
            "\n",
            "  [[2.48000000e+02 2.21000000e+02 1.04142883e+02]\n",
            "   [2.48000000e+02 2.21000000e+02 1.04142883e+02]\n",
            "   [2.47000000e+02 2.20000000e+02 1.03142883e+02]\n",
            "   ...\n",
            "   [2.47071442e+02 2.24270401e+02 1.69673523e+02]\n",
            "   [2.47000000e+02 2.26000000e+02 1.71275558e+02]\n",
            "   [2.47045929e+02 2.26071442e+02 1.73071442e+02]]\n",
            "\n",
            "  [[2.47642822e+02 2.20642822e+02 1.05642822e+02]\n",
            "   [2.47045914e+02 2.20045914e+02 1.05045914e+02]\n",
            "   [2.46642822e+02 2.19642822e+02 1.04642822e+02]\n",
            "   ...\n",
            "   [2.47719345e+02 2.25280655e+02 1.71000000e+02]\n",
            "   [2.47045929e+02 2.26071442e+02 1.73071442e+02]\n",
            "   [2.47000000e+02 2.27000000e+02 1.75173553e+02]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings."
      ],
      "metadata": {
        "id": "cWmO7vv1PKka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0. Building a transfer learning model using the Keras Functional API\n",
        "\n",
        "Alight, our data is tensor-ified, let's build a model.\n",
        "\n",
        "To do so, we're going to be using the `tf.keras.applications` module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate the pretrained model object by choosing a target model such as `EfficientNetB0` from `tf.keras.applications`, setting the `include_top` to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all of the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect ?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some of comp vis models such as `ResNetV250` require their inputs to be between 0 & 1."
      ],
      "metadata": {
        "id": "pKbfEgiLPebN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the pre-trained weights remain same)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create the inputs into the base model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='input_layer')\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to our base model\n",
        "x = base_model(inputs)\n",
        "# check data shape after passing into base model\n",
        "print(f'Shape after base_model: {x.shape}')\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computation)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "print(f'After Global Average Pooling 2D:{x.shape}')\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax', name='output_layer')(x)\n",
        "\n",
        "# 8. Combine the inputs and outputs into our model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 10. Fit the model\n",
        "history_0 = model_0.fit(train_data_10_percent,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_10_percent),\n",
        "                        validation_data=test_data_10_percent,\n",
        "                        validation_steps=len(test_data_10_percent),\n",
        "                        callbacks=[create_tensorboard_callback('transfer_learning',\n",
        "                                                               '10_percent_feature_extraction')])"
      ],
      "metadata": {
        "id": "DE9axB3KSmMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0757a1e-4db0-467a-c115-0f46671966fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n",
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After Global Average Pooling 2D:(None, 1280)\n",
            "Saving Tensorboard log files to: transfer_learning/10_percent_feature_extraction/20221216-055414\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 23s 414ms/step - loss: 1.8589 - accuracy: 0.4573 - val_loss: 1.2955 - val_accuracy: 0.7624\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 8s 320ms/step - loss: 1.0764 - accuracy: 0.7840 - val_loss: 0.8616 - val_accuracy: 0.8240\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 8s 323ms/step - loss: 0.7764 - accuracy: 0.8373 - val_loss: 0.6933 - val_accuracy: 0.8428\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 8s 315ms/step - loss: 0.6319 - accuracy: 0.8680 - val_loss: 0.6078 - val_accuracy: 0.8540\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 8s 316ms/step - loss: 0.5422 - accuracy: 0.8840 - val_loss: 0.5519 - val_accuracy: 0.8636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, we get 88% Training accuracy and 86% Validation accuracy. Not Bad !"
      ],
      "metadata": {
        "id": "FCD2j9LLgHPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next would be to plot the loss curves using Helper Function,"
      ],
      "metadata": {
        "id": "gpv6gLdrgOXx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LUml8uNNgUjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}