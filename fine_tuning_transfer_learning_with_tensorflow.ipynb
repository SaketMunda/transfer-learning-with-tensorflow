{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO9VfzD/xBYHSRm42lV5aDx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/transfer-learning-with-tensorflow/blob/master/fine_tuning_transfer_learning_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow : Fine Tuning\n",
        "\n",
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food vision project (using only 10% of original dataset) than building our own model from scratch.\n",
        "\n",
        "Now, we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "*Feature extraction transfer learning vs. fine-tuning transfer learning. The main difference between the two is that in fine-tuning, more layers of the pre-trained model get unfrozen and tuned on custom data. This fine-tuning usually takes more data than feature extraction to be effective.*"
      ],
      "metadata": {
        "id": "STYzc-8ZGhqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ðŸ’¡ **This time we will use the helper functions to speed up our steps in learning**"
      ],
      "metadata": {
        "id": "YHIrqFznIW1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the Helper functions"
      ],
      "metadata": {
        "id": "eE_H8bZLIq8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from Github\n",
        "!wget https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, unzip_data, walk_through_dir, plot_loss_curves"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Nsxn6zI1lG",
        "outputId": "67ef4b78-1039-4f29-840f-b9526171e550"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-19 04:49:03--  https://raw.githubusercontent.com/SaketMunda/ml-helpers/master/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2904 (2.8K) [text/plain]\n",
            "Saving to: â€˜helper_functions.pyâ€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]   2.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-19 04:49:03 (46.6 MB/s) - â€˜helper_functions.pyâ€™ saved [2904/2904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Food Classes : Working with Less data\n",
        "\n",
        "As in the previous notebook of Transfer Leanring : Feature Extraction, we got good results from less data (10%) of the training data using transfer learning from TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use in-built pretrained models within the `tf.keras.applications` module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, `image_dataset_from_directory()` which is a part of `tf.keras.preprocessing` module.\n",
        "\n",
        "Finally we'll be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The functional API is a more flexible way to create models than the `tf.keras.Sequential`\n",
        "\n",
        "Let's start by downloading the data"
      ],
      "metadata": {
        "id": "9Z7N0tt_JC2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data('10_food_classes_10_percent.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5ovR3QKRHo",
        "outputId": "59e0c284-868b-4c9a-e7af-45e53f2a6f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-17 04:21:42--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.10.128, 142.251.12.128, 172.217.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.10.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_10_percent.zipâ€™\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  23.0MB/s    in 8.0s    \n",
            "\n",
            "2022-12-17 04:21:50 (20.2 MB/s) - â€˜10_food_classes_10_percent.zipâ€™ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through the directory and list number of files\n",
        "walk_through_dir('10_food_classes_10_percent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3SlAZCrKbAE",
        "outputId": "98f63b15-0794-40ee-d44a-a3faca893d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 files in '10_food_classes_10_percent'\n",
            "There are 10 directories and 0 files in '10_food_classes_10_percent/train'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/chicken_curry'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/pizza'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/ramen'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/grilled_salmon'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/chicken_wings'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/fried_rice'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/sushi'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/hamburger'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/steak'\n",
            "There are 0 directories and 75 files in '10_food_classes_10_percent/train/ice_cream'\n",
            "There are 10 directories and 0 files in '10_food_classes_10_percent/test'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/pizza'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/ramen'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/fried_rice'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/sushi'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/hamburger'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/steak'\n",
            "There are 0 directories and 250 files in '10_food_classes_10_percent/test/ice_cream'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same number of files and classes we used in previous notebook."
      ],
      "metadata": {
        "id": "Qz_b4_CSKotm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training and testing directory\n",
        "train_dir = '10_food_classes_10_percent/train/'\n",
        "test_dir = '10_food_classes_10_percent/test/'"
      ],
      "metadata": {
        "id": "pKTTG2hDLrBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some image data, we need a way of loading it into a Tensorflow compatible format.\n",
        "\n",
        "Previously, we've used the `ImageDataGenerator` class. And while this works well and is still very commonly used, this time we're going to use the `image_dataset_from_directory` function.\n",
        "\n",
        "One of the main benefits of using `tf.keras.preprocessing.image_dataset_from_directory()` rather than `ImageDataGenerator` is that it creates a `tf.data.Dataset` object rather than a generator. The main advantage of this is the `tf.data.Dataset` API is much faster and efficient than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "5W-OTNfVL9wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                  image_size=IMG_SHAPE,\n",
        "                                                  label_mode='categorical',\n",
        "                                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                 image_size=IMG_SHAPE,\n",
        "                                                 label_mode='categorical',\n",
        "                                                 batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSN8trhhMway",
        "outputId": "2d1c8e01-65e3-40eb-8db5-08cf1f527b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful ! Looks like our dataloaders have found the correct number of images for each Dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory` function are:\n",
        "- `directory`\n",
        "- `image_size`\n",
        "- `batch_size`"
      ],
      "metadata": {
        "id": "fxpB4afwNRV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if we check the datatype of the preprocessed dataset\n",
        "train_data_10_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSPzMR7aOHaD",
        "outputId": "d0fab52a-41d9-42fa-dac9-526bb2dd346e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's Batch Dataset"
      ],
      "metadata": {
        "id": "x3n5eA58ONgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the classes\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEPxjDtmOcEf",
        "outputId": "2371a3f2-e04b-423a-cd41-8bf8190efae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or if we wanted to see an example of batch of data, we could use the `take()` method"
      ],
      "metadata": {
        "id": "c05996fLOfDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDp1gSWqOsq3",
        "outputId": "cdab7b8a-5fe6-4ce4-ef9b-587ec9938ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[237.        222.        193.       ]\n",
            "   [235.2551    220.85204   191.85204  ]\n",
            "   [232.5051    218.5051    189.93367  ]\n",
            "   ...\n",
            "   [238.28062   224.70915   187.49489  ]\n",
            "   [239.        225.        190.       ]\n",
            "   [240.        226.        191.       ]]\n",
            "\n",
            "  [[254.90816   245.02551   211.2347   ]\n",
            "   [251.92856   240.71939   208.71939  ]\n",
            "   [249.34184   238.34184   206.37245  ]\n",
            "   ...\n",
            "   [238.0153    224.0153    185.0153   ]\n",
            "   [238.07144   224.07144   185.2143   ]\n",
            "   [239.35718   225.35718   187.69385  ]]\n",
            "\n",
            "  [[255.        249.21428   211.57143  ]\n",
            "   [255.        249.21428   211.57143  ]\n",
            "   [254.95409   249.33673   211.95409  ]\n",
            "   ...\n",
            "   [237.21426   224.21426   181.78569  ]\n",
            "   [238.0153    224.60205   182.24487  ]\n",
            "   [239.86226   224.9388    182.79587  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[189.92862    83.5714     47.51019  ]\n",
            "   [188.12755    81.28569    39.897896 ]\n",
            "   [191.10204    87.576546   36.530567 ]\n",
            "   ...\n",
            "   [255.        237.6431    190.71472  ]\n",
            "   [252.69905   238.99515   193.61261  ]\n",
            "   [254.72453   250.08713   205.08716  ]]\n",
            "\n",
            "  [[185.83678    79.836784   40.076557 ]\n",
            "   [193.85715    88.79082    42.132652 ]\n",
            "   [195.60208    92.44395    40.586765 ]\n",
            "   ...\n",
            "   [232.4029    214.91817   170.4182   ]\n",
            "   [242.07654   230.08165   187.93365  ]\n",
            "   [249.29587   244.72446   202.29584  ]]\n",
            "\n",
            "  [[191.58679    88.58679    45.127563 ]\n",
            "   [197.63792    92.637924   44.852207 ]\n",
            "   [203.91849   103.90834    48.984848 ]\n",
            "   ...\n",
            "   [211.80579   186.81078   140.02507  ]\n",
            "   [212.04036   193.2801    146.82597  ]\n",
            "   [236.47981   223.30626   174.94908  ]]]\n",
            "\n",
            "\n",
            " [[[192.        239.        245.       ]\n",
            "   [192.        239.        247.       ]\n",
            "   [189.78572   236.57143   247.21428  ]\n",
            "   ...\n",
            "   [143.71938   132.71938   102.71938  ]\n",
            "   [142.64285   131.64285   103.64286  ]\n",
            "   [143.22961   132.22961   104.229614 ]]\n",
            "\n",
            "  [[191.        238.        244.       ]\n",
            "   [191.07143   238.07143   246.07143  ]\n",
            "   [190.80103   237.58673   248.22958  ]\n",
            "   ...\n",
            "   [144.94388   131.21426   101.4031   ]\n",
            "   [144.        130.        101.       ]\n",
            "   [144.        130.        101.       ]]\n",
            "\n",
            "  [[191.78572   238.78572   246.35715  ]\n",
            "   [192.7296    239.7296    247.7296   ]\n",
            "   [191.78572   238.57144   249.2143   ]\n",
            "   ...\n",
            "   [144.99998   130.42854    97.64284  ]\n",
            "   [144.78572   130.         99.42857  ]\n",
            "   [144.78572   130.         99.42857  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[184.56639   182.48985   160.63274  ]\n",
            "   [184.22461   182.01031   161.4389   ]\n",
            "   [174.78078   172.56648   151.99507  ]\n",
            "   ...\n",
            "   [101.61742    71.61742    35.617416 ]\n",
            "   [102.5715     72.5715     36.571503 ]\n",
            "   [103.489555   73.489555   37.489555 ]]\n",
            "\n",
            "  [[189.37753   186.42345   167.9949   ]\n",
            "   [193.14282   190.14282   173.       ]\n",
            "   [189.08672   186.08672   168.9439   ]\n",
            "   ...\n",
            "   [110.06641    80.06641    44.06641  ]\n",
            "   [106.07664    76.07664    40.076633 ]\n",
            "   [105.923355   75.923355   39.92336  ]]\n",
            "\n",
            "  [[187.28577   184.28577   168.82658  ]\n",
            "   [191.07657   188.07657   173.07657  ]\n",
            "   [191.99492   188.35207   175.28062  ]\n",
            "   ...\n",
            "   [108.23471    78.23471    42.234715 ]\n",
            "   [107.50507    77.50507    41.505074 ]\n",
            "   [103.14288    73.14288    37.142883 ]]]\n",
            "\n",
            "\n",
            " [[[ 77.94388    69.94388    67.94388  ]\n",
            "   [ 87.45408    79.45408    77.45408  ]\n",
            "   [ 88.005104   79.57653    77.79082  ]\n",
            "   ...\n",
            "   [ 40.36217    28.933643   24.076588 ]\n",
            "   [ 36.857117   27.         25.928558 ]\n",
            "   [ 29.872402   23.872402   25.872402 ]]\n",
            "\n",
            "  [[ 78.831635   70.831635   68.831635 ]\n",
            "   [ 91.79592    83.79592    81.79592  ]\n",
            "   [ 91.67347    83.67347    81.67347  ]\n",
            "   ...\n",
            "   [ 42.056015   30.627487   25.770432 ]\n",
            "   [ 36.785675   26.928558   25.857117 ]\n",
            "   [ 32.239727   23.239729   25.045916 ]]\n",
            "\n",
            "  [[ 72.51021    64.15306    64.938774 ]\n",
            "   [ 87.62755    80.05612    78.484695 ]\n",
            "   [ 91.61735    83.448975   81.95408  ]\n",
            "   ...\n",
            "   [ 43.025406   31.596878   27.16835  ]\n",
            "   [ 37.19898    27.198977   26.198977 ]\n",
            "   [ 33.933647   24.933647   25.933647 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 52.637653   31.147799   25.999891 ]\n",
            "   [ 59.300976   36.15803    31.51524  ]\n",
            "   [ 59.68875    36.19378    31.688728 ]\n",
            "   ...\n",
            "   [103.0205     31.449026    7.234762 ]\n",
            "   [105.015366   33.01537     9.015368 ]\n",
            "   [104.351845   32.351845    8.351845 ]]\n",
            "\n",
            "  [[ 50.617447   19.12247    11.382657 ]\n",
            "   [ 52.21434    18.862232   11.71935  ]\n",
            "   [ 56.755123   22.999962   16.056055 ]\n",
            "   ...\n",
            "   [103.42877    31.8573      7.643036 ]\n",
            "   [109.13778    37.13778    13.137779 ]\n",
            "   [107.40812    35.40812    11.408121 ]]\n",
            "\n",
            "  [[ 63.459194   20.744839    8.38766  ]\n",
            "   [ 66.9747     22.352173   10.591902 ]\n",
            "   [ 68.5666     23.699165   12.061349 ]\n",
            "   ...\n",
            "   [104.35724    32.785767    8.571503 ]\n",
            "   [106.73455    34.73455    10.734549 ]\n",
            "   [103.69887    31.698864    7.698865 ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 16.285713   13.285715    4.285714 ]\n",
            "   [ 15.214286   12.214286    3.2142859]\n",
            "   [ 14.285714   11.285714    3.8571427]\n",
            "   ...\n",
            "   [ 37.066334   28.066332   21.066332 ]\n",
            "   [ 35.44894    26.44894    19.44894  ]\n",
            "   [ 33.816326   24.816328   17.816328 ]]\n",
            "\n",
            "  [[ 14.071428   14.071428    4.0714283]\n",
            "   [ 15.         15.          7.       ]\n",
            "   [ 15.         15.          7.       ]\n",
            "   ...\n",
            "   [ 37.17347    28.17347    21.17347  ]\n",
            "   [ 36.22447    27.22447    20.22447  ]\n",
            "   [ 37.147953   28.147951   21.147951 ]]\n",
            "\n",
            "  [[ 13.357142   14.785714    7.       ]\n",
            "   [ 12.32653    13.755102    5.9693875]\n",
            "   [ 11.928571   13.357142    6.806122 ]\n",
            "   ...\n",
            "   [ 33.928543   24.928545   18.357117 ]\n",
            "   [ 27.127468   18.127468   11.556039 ]\n",
            "   [ 25.780607   16.780607   10.209179 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 60.867374   43.295902   29.081638 ]\n",
            "   [ 51.974377   33.974377   19.974377 ]\n",
            "   [ 47.739605   30.356968   15.12224  ]\n",
            "   ...\n",
            "   [ 21.025587   12.454115    3.6683788]\n",
            "   [ 28.357239   19.785767   11.0000305]\n",
            "   [ 26.780655   18.209183    9.423446 ]]\n",
            "\n",
            "  [[ 52.433964   36.433964   21.433962 ]\n",
            "   [ 71.95437    55.954376   40.954376 ]\n",
            "   [ 74.316345   58.316345   42.530632 ]\n",
            "   ...\n",
            "   [ 24.683645   15.469351    6.4693503]\n",
            "   [ 22.923426   12.923426    3.9234262]\n",
            "   [ 25.943926   15.943927    5.943927 ]]\n",
            "\n",
            "  [[ 68.57594    52.575947   37.575947 ]\n",
            "   [ 80.16235    64.16235    48.162354 ]\n",
            "   [ 59.473656   43.47365    27.473652 ]\n",
            "   ...\n",
            "   [ 26.08167    16.08167     6.867377 ]\n",
            "   [ 24.40819    14.408191    4.4081907]\n",
            "   [ 28.351814   18.351814    8.351814 ]]]\n",
            "\n",
            "\n",
            " [[[196.61224   172.61224   146.61224  ]\n",
            "   [198.9796    174.9796    148.9796   ]\n",
            "   [199.09694   172.66837   149.88264  ]\n",
            "   ...\n",
            "   [116.09187    73.01535    57.244915 ]\n",
            "   [116.352066   73.352066   57.352066 ]\n",
            "   [114.77025    71.77025    55.770245 ]]\n",
            "\n",
            "  [[196.7602    172.7602    146.7602   ]\n",
            "   [198.9949    174.9949    150.9949   ]\n",
            "   [205.81122   179.59694   157.0255   ]\n",
            "   ...\n",
            "   [119.18372    78.11229    60.25515  ]\n",
            "   [113.80112    72.80112    54.801113 ]\n",
            "   [119.91821    78.91821    60.918213 ]]\n",
            "\n",
            "  [[198.70407   173.70407   152.13264  ]\n",
            "   [205.37245   180.37245   158.80103  ]\n",
            "   [206.61734   179.61734   159.04591  ]\n",
            "   ...\n",
            "   [103.19384    62.8367     42.19384  ]\n",
            "   [115.45409    75.09694    54.882656 ]\n",
            "   [121.00532    80.64818    62.005318 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[177.90308   154.68881   124.331604 ]\n",
            "   [179.28087   155.28087   127.28087  ]\n",
            "   [170.10213   145.33685   118.05623  ]\n",
            "   ...\n",
            "   [ 40.6682      4.382619   10.382619 ]\n",
            "   [ 25.969263    3.0255196   8.826502 ]\n",
            "   [ 12.5866165   1.5816189   4.795913 ]]\n",
            "\n",
            "  [[180.55614   159.55614   128.55614  ]\n",
            "   [176.68367   155.68367   126.68367  ]\n",
            "   [188.03566   163.6071    137.82138  ]\n",
            "   ...\n",
            "   [ 35.341717    3.484662    8.326532 ]\n",
            "   [ 24.4897      4.0663376   8.852013 ]\n",
            "   [  9.719161    2.6428223   4.8825426]]\n",
            "\n",
            "  [[183.59187   164.59187   132.59187  ]\n",
            "   [178.82648   157.82648   128.82648  ]\n",
            "   [181.41843   159.77556   133.41843  ]\n",
            "   ...\n",
            "   [ 36.92344     7.2806473  11.852119 ]\n",
            "   [ 21.377432    2.9285583   6.7601576]\n",
            "   [  6.469263    1.8979741   3.5407963]]]\n",
            "\n",
            "\n",
            " [[[ 30.158163   15.158163    8.158163 ]\n",
            "   [ 31.954082   16.954082   11.954082 ]\n",
            "   [ 30.928572   15.928572   11.357143 ]\n",
            "   ...\n",
            "   [166.50029    94.0054     55.347412 ]\n",
            "   [118.32134    52.535667   18.035576 ]\n",
            "   [112.566734   52.923916    1.8369142]]\n",
            "\n",
            "  [[ 29.02551    16.02551     8.02551  ]\n",
            "   [ 33.071426   18.071428   11.071428 ]\n",
            "   [ 30.357143   15.357142   10.357142 ]\n",
            "   ...\n",
            "   [161.99466    89.99467    48.280552 ]\n",
            "   [114.1429     49.285793   11.270445 ]\n",
            "   [138.22504    78.22503    26.796322 ]]\n",
            "\n",
            "  [[ 31.57653    18.790817    9.147959 ]\n",
            "   [ 32.086735   19.086735   10.086735 ]\n",
            "   [ 29.091837   14.47449     7.0459185]\n",
            "   ...\n",
            "   [136.90222    68.38191    21.80548  ]\n",
            "   [119.28577    56.969486   13.699069 ]\n",
            "   [142.04532    84.06065    37.69833  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[107.6685     77.6685     40.09703  ]\n",
            "   [107.45424    77.45424    39.882767 ]\n",
            "   [106.45426    76.45426    40.88279  ]\n",
            "   ...\n",
            "   [169.43344   162.86197   169.86197  ]\n",
            "   [165.8008    156.44359   164.44359  ]\n",
            "   [161.00987   151.65266   159.65266  ]]\n",
            "\n",
            "  [[ 99.50517    69.50517    31.505167 ]\n",
            "   [100.4337     71.4337     31.433699 ]\n",
            "   [102.92859    73.92859    33.928585 ]\n",
            "   ...\n",
            "   [146.18347   135.25491   139.04059  ]\n",
            "   [140.58156   129.51012   135.23456  ]\n",
            "   [135.67336   123.40812   129.19882  ]]\n",
            "\n",
            "  [[105.46924    77.46924    37.46924  ]\n",
            "   [103.066216   75.066216   35.066216 ]\n",
            "   [105.21933    78.21933    35.219326 ]\n",
            "   ...\n",
            "   [138.07153   126.07153   126.07153  ]\n",
            "   [139.4031    124.4031    127.4031   ]\n",
            "   [143.19911   128.19911   131.19911  ]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings."
      ],
      "metadata": {
        "id": "cWmO7vv1PKka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0. Building a transfer learning model using the Keras Functional API\n",
        "\n",
        "Alight, our data is tensor-ified, let's build a model.\n",
        "\n",
        "To do so, we're going to be using the `tf.keras.applications` module as it contains a series of already trained (on ImageNet) computer vision models as well as the Keras Functional API to construct our model.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Instantiate the pretrained model object by choosing a target model such as `EfficientNetB0` from `tf.keras.applications`, setting the `include_top` to `False` (we do this because we're going to create our own top, which are the output layers for the model).\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all of the weights in the pre-trained model.\n",
        "3. Define an input layer for our model, for example, what shape of data should our model expect ?\n",
        "4. [Optional] Normalize the inputs to our model if it requires. Some of comp vis models such as `ResNetV250` require their inputs to be between 0 & 1."
      ],
      "metadata": {
        "id": "pKbfEgiLPebN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the pre-trained weights remain same)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create the inputs into the base model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='input_layer')\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to our base model\n",
        "x = base_model(inputs)\n",
        "# check data shape after passing into base model\n",
        "print(f'Shape after base_model: {x.shape}')\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computation)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "print(f'After Global Average Pooling 2D:{x.shape}')\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax', name='output_layer')(x)\n",
        "\n",
        "# 8. Combine the inputs and outputs into our model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# 10. Fit the model\n",
        "history_0 = model_0.fit(train_data_10_percent,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch=len(train_data_10_percent),\n",
        "                        validation_data=test_data_10_percent,\n",
        "                        validation_steps=len(test_data_10_percent),\n",
        "                        callbacks=[create_tensorboard_callback('transfer_learning',\n",
        "                                                               '10_percent_feature_extraction')])"
      ],
      "metadata": {
        "id": "DE9axB3KSmMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e47ffa-2785-44ce-db75-dcfb43a7620a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 2s 0us/step\n",
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After Global Average Pooling 2D:(None, 1280)\n",
            "Saving Tensorboard log files to: transfer_learning/10_percent_feature_extraction/20221217-042201\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 24s 449ms/step - loss: 1.9174 - accuracy: 0.3880 - val_loss: 1.3188 - val_accuracy: 0.7256\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 10s 407ms/step - loss: 1.1167 - accuracy: 0.7533 - val_loss: 0.8780 - val_accuracy: 0.8204\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 12s 518ms/step - loss: 0.8017 - accuracy: 0.8213 - val_loss: 0.7032 - val_accuracy: 0.8428\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 8s 325ms/step - loss: 0.6513 - accuracy: 0.8600 - val_loss: 0.6125 - val_accuracy: 0.8520\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 8s 344ms/step - loss: 0.5528 - accuracy: 0.8840 - val_loss: 0.5567 - val_accuracy: 0.8568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, we get 88% Training accuracy and 86% Validation accuracy. Not Bad !"
      ],
      "metadata": {
        "id": "FCD2j9LLgHPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next would be to plot the loss curves using Helper Function,"
      ],
      "metadata": {
        "id": "gpv6gLdrgOXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the loss and accuracy curves\n",
        "plot_loss_curves(history_0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "l9KBU76wUWNb",
        "outputId": "bb479621-7635-4c96-ea6e-d9c04b2d3222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like if we increase the number of `epochs` or leave our model to train little longer we might achieve more decrease in loss since it's continously decreasing which is good sign, and vice-versa for accuracy, accuracy curve is almost touching 0.9"
      ],
      "metadata": {
        "id": "vyUrqv6PUpTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to note the kind of transfer learning we used here is feature extraction transfer learning, similar to what we did with the TensorFlow Hub models.\n",
        "\n",
        "In other words, we passed our custom data to an already pre-trained model (`EfficientNetB0`), asked it \"What patterns do you see?\" and then put our own output layer on top to make sure the outputs were tailored to our desired number of clases.\n",
        "\n",
        "\n",
        "We have also used the Keras Functional API to build our model rather than Sequential API. For now, the benefits of this may not seem clear but when start building more sophistictaed modesl, you'll probably want to use the Functional API. So it's important to get familiar now.\n",
        "\n",
        "> ðŸ’¡ **What I assume** : *If we use **Functional API** for transfer learning models, due to it's flexibility we can alter anything according to our own problem which I guess would be helpful in fine-tuning*.\n",
        "\n",
        "\n",
        "Let's inspect the model layers, we'll start with the base."
      ],
      "metadata": {
        "id": "m-o2W5fYVDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the layers in our base_model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1S4pZcwWFL7",
        "outputId": "a4b165ad-7ba9-4e62-ae31-30f137767696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1\n",
            "1 rescaling\n",
            "2 normalization\n",
            "3 tf.math.truediv\n",
            "4 stem_conv_pad\n",
            "5 stem_conv\n",
            "6 stem_bn\n",
            "7 stem_activation\n",
            "8 block1a_dwconv\n",
            "9 block1a_bn\n",
            "10 block1a_activation\n",
            "11 block1a_se_squeeze\n",
            "12 block1a_se_reshape\n",
            "13 block1a_se_reduce\n",
            "14 block1a_se_expand\n",
            "15 block1a_se_excite\n",
            "16 block1a_project_conv\n",
            "17 block1a_project_bn\n",
            "18 block2a_expand_conv\n",
            "19 block2a_expand_bn\n",
            "20 block2a_expand_activation\n",
            "21 block2a_dwconv_pad\n",
            "22 block2a_dwconv\n",
            "23 block2a_bn\n",
            "24 block2a_activation\n",
            "25 block2a_se_squeeze\n",
            "26 block2a_se_reshape\n",
            "27 block2a_se_reduce\n",
            "28 block2a_se_expand\n",
            "29 block2a_se_excite\n",
            "30 block2a_project_conv\n",
            "31 block2a_project_bn\n",
            "32 block2b_expand_conv\n",
            "33 block2b_expand_bn\n",
            "34 block2b_expand_activation\n",
            "35 block2b_dwconv\n",
            "36 block2b_bn\n",
            "37 block2b_activation\n",
            "38 block2b_se_squeeze\n",
            "39 block2b_se_reshape\n",
            "40 block2b_se_reduce\n",
            "41 block2b_se_expand\n",
            "42 block2b_se_excite\n",
            "43 block2b_project_conv\n",
            "44 block2b_project_bn\n",
            "45 block2b_drop\n",
            "46 block2b_add\n",
            "47 block3a_expand_conv\n",
            "48 block3a_expand_bn\n",
            "49 block3a_expand_activation\n",
            "50 block3a_dwconv_pad\n",
            "51 block3a_dwconv\n",
            "52 block3a_bn\n",
            "53 block3a_activation\n",
            "54 block3a_se_squeeze\n",
            "55 block3a_se_reshape\n",
            "56 block3a_se_reduce\n",
            "57 block3a_se_expand\n",
            "58 block3a_se_excite\n",
            "59 block3a_project_conv\n",
            "60 block3a_project_bn\n",
            "61 block3b_expand_conv\n",
            "62 block3b_expand_bn\n",
            "63 block3b_expand_activation\n",
            "64 block3b_dwconv\n",
            "65 block3b_bn\n",
            "66 block3b_activation\n",
            "67 block3b_se_squeeze\n",
            "68 block3b_se_reshape\n",
            "69 block3b_se_reduce\n",
            "70 block3b_se_expand\n",
            "71 block3b_se_excite\n",
            "72 block3b_project_conv\n",
            "73 block3b_project_bn\n",
            "74 block3b_drop\n",
            "75 block3b_add\n",
            "76 block4a_expand_conv\n",
            "77 block4a_expand_bn\n",
            "78 block4a_expand_activation\n",
            "79 block4a_dwconv_pad\n",
            "80 block4a_dwconv\n",
            "81 block4a_bn\n",
            "82 block4a_activation\n",
            "83 block4a_se_squeeze\n",
            "84 block4a_se_reshape\n",
            "85 block4a_se_reduce\n",
            "86 block4a_se_expand\n",
            "87 block4a_se_excite\n",
            "88 block4a_project_conv\n",
            "89 block4a_project_bn\n",
            "90 block4b_expand_conv\n",
            "91 block4b_expand_bn\n",
            "92 block4b_expand_activation\n",
            "93 block4b_dwconv\n",
            "94 block4b_bn\n",
            "95 block4b_activation\n",
            "96 block4b_se_squeeze\n",
            "97 block4b_se_reshape\n",
            "98 block4b_se_reduce\n",
            "99 block4b_se_expand\n",
            "100 block4b_se_excite\n",
            "101 block4b_project_conv\n",
            "102 block4b_project_bn\n",
            "103 block4b_drop\n",
            "104 block4b_add\n",
            "105 block4c_expand_conv\n",
            "106 block4c_expand_bn\n",
            "107 block4c_expand_activation\n",
            "108 block4c_dwconv\n",
            "109 block4c_bn\n",
            "110 block4c_activation\n",
            "111 block4c_se_squeeze\n",
            "112 block4c_se_reshape\n",
            "113 block4c_se_reduce\n",
            "114 block4c_se_expand\n",
            "115 block4c_se_excite\n",
            "116 block4c_project_conv\n",
            "117 block4c_project_bn\n",
            "118 block4c_drop\n",
            "119 block4c_add\n",
            "120 block5a_expand_conv\n",
            "121 block5a_expand_bn\n",
            "122 block5a_expand_activation\n",
            "123 block5a_dwconv\n",
            "124 block5a_bn\n",
            "125 block5a_activation\n",
            "126 block5a_se_squeeze\n",
            "127 block5a_se_reshape\n",
            "128 block5a_se_reduce\n",
            "129 block5a_se_expand\n",
            "130 block5a_se_excite\n",
            "131 block5a_project_conv\n",
            "132 block5a_project_bn\n",
            "133 block5b_expand_conv\n",
            "134 block5b_expand_bn\n",
            "135 block5b_expand_activation\n",
            "136 block5b_dwconv\n",
            "137 block5b_bn\n",
            "138 block5b_activation\n",
            "139 block5b_se_squeeze\n",
            "140 block5b_se_reshape\n",
            "141 block5b_se_reduce\n",
            "142 block5b_se_expand\n",
            "143 block5b_se_excite\n",
            "144 block5b_project_conv\n",
            "145 block5b_project_bn\n",
            "146 block5b_drop\n",
            "147 block5b_add\n",
            "148 block5c_expand_conv\n",
            "149 block5c_expand_bn\n",
            "150 block5c_expand_activation\n",
            "151 block5c_dwconv\n",
            "152 block5c_bn\n",
            "153 block5c_activation\n",
            "154 block5c_se_squeeze\n",
            "155 block5c_se_reshape\n",
            "156 block5c_se_reduce\n",
            "157 block5c_se_expand\n",
            "158 block5c_se_excite\n",
            "159 block5c_project_conv\n",
            "160 block5c_project_bn\n",
            "161 block5c_drop\n",
            "162 block5c_add\n",
            "163 block6a_expand_conv\n",
            "164 block6a_expand_bn\n",
            "165 block6a_expand_activation\n",
            "166 block6a_dwconv_pad\n",
            "167 block6a_dwconv\n",
            "168 block6a_bn\n",
            "169 block6a_activation\n",
            "170 block6a_se_squeeze\n",
            "171 block6a_se_reshape\n",
            "172 block6a_se_reduce\n",
            "173 block6a_se_expand\n",
            "174 block6a_se_excite\n",
            "175 block6a_project_conv\n",
            "176 block6a_project_bn\n",
            "177 block6b_expand_conv\n",
            "178 block6b_expand_bn\n",
            "179 block6b_expand_activation\n",
            "180 block6b_dwconv\n",
            "181 block6b_bn\n",
            "182 block6b_activation\n",
            "183 block6b_se_squeeze\n",
            "184 block6b_se_reshape\n",
            "185 block6b_se_reduce\n",
            "186 block6b_se_expand\n",
            "187 block6b_se_excite\n",
            "188 block6b_project_conv\n",
            "189 block6b_project_bn\n",
            "190 block6b_drop\n",
            "191 block6b_add\n",
            "192 block6c_expand_conv\n",
            "193 block6c_expand_bn\n",
            "194 block6c_expand_activation\n",
            "195 block6c_dwconv\n",
            "196 block6c_bn\n",
            "197 block6c_activation\n",
            "198 block6c_se_squeeze\n",
            "199 block6c_se_reshape\n",
            "200 block6c_se_reduce\n",
            "201 block6c_se_expand\n",
            "202 block6c_se_excite\n",
            "203 block6c_project_conv\n",
            "204 block6c_project_bn\n",
            "205 block6c_drop\n",
            "206 block6c_add\n",
            "207 block6d_expand_conv\n",
            "208 block6d_expand_bn\n",
            "209 block6d_expand_activation\n",
            "210 block6d_dwconv\n",
            "211 block6d_bn\n",
            "212 block6d_activation\n",
            "213 block6d_se_squeeze\n",
            "214 block6d_se_reshape\n",
            "215 block6d_se_reduce\n",
            "216 block6d_se_expand\n",
            "217 block6d_se_excite\n",
            "218 block6d_project_conv\n",
            "219 block6d_project_bn\n",
            "220 block6d_drop\n",
            "221 block6d_add\n",
            "222 block7a_expand_conv\n",
            "223 block7a_expand_bn\n",
            "224 block7a_expand_activation\n",
            "225 block7a_dwconv\n",
            "226 block7a_bn\n",
            "227 block7a_activation\n",
            "228 block7a_se_squeeze\n",
            "229 block7a_se_reshape\n",
            "230 block7a_se_reduce\n",
            "231 block7a_se_expand\n",
            "232 block7a_se_excite\n",
            "233 block7a_project_conv\n",
            "234 block7a_project_bn\n",
            "235 top_conv\n",
            "236 top_bn\n",
            "237 top_activation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So these are the list of layers that are used in the pre-trained `base_model`.\n",
        "These are hand-coded by the creators of these model adding each layer manually and tested on `ImageNet` dataset. But transfer-learning makes it available for us to use this in our own dataset.\n",
        "\n",
        "\n",
        "How about the summary of the `base_model`?"
      ],
      "metadata": {
        "id": "4rSnk42RWL5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMCx0u98XfIJ",
        "outputId": "cf73d07c-5d66-4f49-869f-ca7b7f1d6df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnetb0\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, None, None,   0           ['input_1[0][0]']                \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, None, None,   7           ['rescaling[0][0]']              \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (None, None, None,   0           ['normalization[0][0]']          \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding2D)  (None, None, None,   0           ['tf.math.truediv[0][0]']        \n",
            "                                3)                                                                \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, None, None,   864         ['stem_conv_pad[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, None, None,   128         ['stem_conv[0][0]']              \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, None, None,   0           ['stem_bn[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseConv2  (None, None, None,   288        ['stem_activation[0][0]']        \n",
            " D)                             32)                                                               \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormalization  (None, None, None,   128        ['block1a_dwconv[0][0]']         \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_activation (Activation  (None, None, None,   0          ['block1a_bn[0][0]']             \n",
            " )                              32)                                                               \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multiply)   (None, None, None,   0           ['block1a_activation[0][0]',     \n",
            "                                32)                               'block1a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, None, None,   512         ['block1a_se_excite[0][0]']      \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, None, None,   64         ['block1a_project_conv[0][0]']   \n",
            " lization)                      16)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, None, None,   1536        ['block1a_project_bn[0][0]']     \n",
            "                                96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, None, None,   384        ['block2a_expand_conv[0][0]']    \n",
            " ization)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, None, None,   0          ['block2a_expand_bn[0][0]']      \n",
            " ivation)                       96)                                                               \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block2a_expand_activation[0][0]\n",
            " g2D)                           96)                              ']                               \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseConv2  (None, None, None,   864        ['block2a_dwconv_pad[0][0]']     \n",
            " D)                             96)                                                               \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormalization  (None, None, None,   384        ['block2a_dwconv[0][0]']         \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_activation (Activation  (None, None, None,   0          ['block2a_bn[0][0]']             \n",
            " )                              96)                                                               \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multiply)   (None, None, None,   0           ['block2a_activation[0][0]',     \n",
            "                                96)                               'block2a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, None, None,   2304        ['block2a_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, None, None,   96         ['block2a_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, None, None,   3456        ['block2a_project_bn[0][0]']     \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, None, None,   576        ['block2b_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, None, None,   0          ['block2b_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseConv2  (None, None, None,   1296       ['block2b_expand_activation[0][0]\n",
            " D)                             144)                             ']                               \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormalization  (None, None, None,   576        ['block2b_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_activation (Activation  (None, None, None,   0          ['block2b_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multiply)   (None, None, None,   0           ['block2b_activation[0][0]',     \n",
            "                                144)                              'block2b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, None, None,   3456        ['block2b_se_excite[0][0]']      \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, None, None,   96         ['block2b_project_conv[0][0]']   \n",
            " lization)                      24)                                                               \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, None, None,   0           ['block2b_project_bn[0][0]']     \n",
            "                                24)                                                               \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, None, None,   0           ['block2b_drop[0][0]',           \n",
            "                                24)                               'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, None, None,   3456        ['block2b_add[0][0]']            \n",
            "                                144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, None, None,   576        ['block3a_expand_conv[0][0]']    \n",
            " ization)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, None, None,   0          ['block3a_expand_bn[0][0]']      \n",
            " ivation)                       144)                                                              \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block3a_expand_activation[0][0]\n",
            " g2D)                           144)                             ']                               \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseConv2  (None, None, None,   3600       ['block3a_dwconv_pad[0][0]']     \n",
            " D)                             144)                                                              \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormalization  (None, None, None,   576        ['block3a_dwconv[0][0]']         \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_activation (Activation  (None, None, None,   0          ['block3a_bn[0][0]']             \n",
            " )                              144)                                                              \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multiply)   (None, None, None,   0           ['block3a_activation[0][0]',     \n",
            "                                144)                              'block3a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, None, None,   5760        ['block3a_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, None, None,   160        ['block3a_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, None, None,   9600        ['block3a_project_bn[0][0]']     \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, None, None,   960        ['block3b_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, None, None,   0          ['block3b_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseConv2  (None, None, None,   6000       ['block3b_expand_activation[0][0]\n",
            " D)                             240)                             ']                               \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormalization  (None, None, None,   960        ['block3b_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_activation (Activation  (None, None, None,   0          ['block3b_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multiply)   (None, None, None,   0           ['block3b_activation[0][0]',     \n",
            "                                240)                              'block3b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, None, None,   9600        ['block3b_se_excite[0][0]']      \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, None, None,   160        ['block3b_project_conv[0][0]']   \n",
            " lization)                      40)                                                               \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, None, None,   0           ['block3b_project_bn[0][0]']     \n",
            "                                40)                                                               \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, None, None,   0           ['block3b_drop[0][0]',           \n",
            "                                40)                               'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, None, None,   9600        ['block3b_add[0][0]']            \n",
            "                                240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, None, None,   960        ['block4a_expand_conv[0][0]']    \n",
            " ization)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, None, None,   0          ['block4a_expand_bn[0][0]']      \n",
            " ivation)                       240)                                                              \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block4a_expand_activation[0][0]\n",
            " g2D)                           240)                             ']                               \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseConv2  (None, None, None,   2160       ['block4a_dwconv_pad[0][0]']     \n",
            " D)                             240)                                                              \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, None, None,   960        ['block4a_dwconv[0][0]']         \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, None, None,   0          ['block4a_bn[0][0]']             \n",
            " )                              240)                                                              \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, None, None,   0           ['block4a_activation[0][0]',     \n",
            "                                240)                              'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, None, None,   19200       ['block4a_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, None, None,   320        ['block4a_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, None, None,   38400       ['block4a_project_bn[0][0]']     \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, None, None,   1920       ['block4b_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, None, None,   0          ['block4b_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4b_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, None, None,   1920       ['block4b_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, None, None,   0          ['block4b_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, None, None,   0           ['block4b_activation[0][0]',     \n",
            "                                480)                              'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, None, None,   38400       ['block4b_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, None, None,   320        ['block4b_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, None, None,   0           ['block4b_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, None, None,   0           ['block4b_drop[0][0]',           \n",
            "                                80)                               'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, None, None,   38400       ['block4b_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, None, None,   1920       ['block4c_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, None, None,   0          ['block4c_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseConv2  (None, None, None,   4320       ['block4c_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, None, None,   1920       ['block4c_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, None, None,   0          ['block4c_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, None, None,   0           ['block4c_activation[0][0]',     \n",
            "                                480)                              'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, None, None,   38400       ['block4c_se_excite[0][0]']      \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, None, None,   320        ['block4c_project_conv[0][0]']   \n",
            " lization)                      80)                                                               \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, None, None,   0           ['block4c_project_bn[0][0]']     \n",
            "                                80)                                                               \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, None, None,   0           ['block4c_drop[0][0]',           \n",
            "                                80)                               'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, None, None,   38400       ['block4c_add[0][0]']            \n",
            "                                480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, None, None,   1920       ['block5a_expand_conv[0][0]']    \n",
            " ization)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, None, None,   0          ['block5a_expand_bn[0][0]']      \n",
            " ivation)                       480)                                                              \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseConv2  (None, None, None,   12000      ['block5a_expand_activation[0][0]\n",
            " D)                             480)                             ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, None, None,   1920       ['block5a_dwconv[0][0]']         \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, None, None,   0          ['block5a_bn[0][0]']             \n",
            " )                              480)                                                              \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, None, None,   0           ['block5a_activation[0][0]',     \n",
            "                                480)                              'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, None, None,   53760       ['block5a_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, None, None,   448        ['block5a_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, None, None,   75264       ['block5a_project_bn[0][0]']     \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, None, None,   2688       ['block5b_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, None, None,   0          ['block5b_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5b_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, None, None,   2688       ['block5b_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, None, None,   0          ['block5b_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, None, None,   0           ['block5b_activation[0][0]',     \n",
            "                                672)                              'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, None, None,   75264       ['block5b_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, None, None,   448        ['block5b_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, None, None,   0           ['block5b_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, None, None,   0           ['block5b_drop[0][0]',           \n",
            "                                112)                              'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, None, None,   75264       ['block5b_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, None, None,   2688       ['block5c_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, None, None,   0          ['block5c_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block5c_expand_activation[0][0]\n",
            " D)                             672)                             ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, None, None,   2688       ['block5c_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, None, None,   0          ['block5c_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, None, None,   0           ['block5c_activation[0][0]',     \n",
            "                                672)                              'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, None, None,   75264       ['block5c_se_excite[0][0]']      \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, None, None,   448        ['block5c_project_conv[0][0]']   \n",
            " lization)                      112)                                                              \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, None, None,   0           ['block5c_project_bn[0][0]']     \n",
            "                                112)                                                              \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, None, None,   0           ['block5c_drop[0][0]',           \n",
            "                                112)                              'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, None, None,   75264       ['block5c_add[0][0]']            \n",
            "                                672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, None, None,   2688       ['block6a_expand_conv[0][0]']    \n",
            " ization)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, None, None,   0          ['block6a_expand_bn[0][0]']      \n",
            " ivation)                       672)                                                              \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPaddin  (None, None, None,   0          ['block6a_expand_activation[0][0]\n",
            " g2D)                           672)                             ']                               \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseConv2  (None, None, None,   16800      ['block6a_dwconv_pad[0][0]']     \n",
            " D)                             672)                                                              \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, None, None,   2688       ['block6a_dwconv[0][0]']         \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, None, None,   0          ['block6a_bn[0][0]']             \n",
            " )                              672)                                                              \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, None, None,   0           ['block6a_activation[0][0]',     \n",
            "                                672)                              'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, None, None,   129024      ['block6a_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, None, None,   768        ['block6a_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, None, None,   221184      ['block6a_project_bn[0][0]']     \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, None, None,   4608       ['block6b_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, None, None,   0          ['block6b_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6b_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, None, None,   4608       ['block6b_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, None, None,   0          ['block6b_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, None, None,   0           ['block6b_activation[0][0]',     \n",
            "                                1152)                             'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, None, None,   221184      ['block6b_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, None, None,   768        ['block6b_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, None, None,   0           ['block6b_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, None, None,   0           ['block6b_drop[0][0]',           \n",
            "                                192)                              'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, None, None,   221184      ['block6b_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, None, None,   4608       ['block6c_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, None, None,   0          ['block6c_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6c_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, None, None,   4608       ['block6c_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, None, None,   0          ['block6c_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, None, None,   0           ['block6c_activation[0][0]',     \n",
            "                                1152)                             'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, None, None,   221184      ['block6c_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, None, None,   768        ['block6c_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, None, None,   0           ['block6c_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, None, None,   0           ['block6c_drop[0][0]',           \n",
            "                                192)                              'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, None, None,   221184      ['block6c_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, None, None,   4608       ['block6d_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, None, None,   0          ['block6d_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseConv2  (None, None, None,   28800      ['block6d_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, None, None,   4608       ['block6d_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, None, None,   0          ['block6d_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, None, None,   0           ['block6d_activation[0][0]',     \n",
            "                                1152)                             'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, None, None,   221184      ['block6d_se_excite[0][0]']      \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, None, None,   768        ['block6d_project_conv[0][0]']   \n",
            " lization)                      192)                                                              \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, None, None,   0           ['block6d_project_bn[0][0]']     \n",
            "                                192)                                                              \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, None, None,   0           ['block6d_drop[0][0]',           \n",
            "                                192)                              'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2D)   (None, None, None,   221184      ['block6d_add[0][0]']            \n",
            "                                1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNormal  (None, None, None,   4608       ['block7a_expand_conv[0][0]']    \n",
            " ization)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_expand_activation (Act  (None, None, None,   0          ['block7a_expand_bn[0][0]']      \n",
            " ivation)                       1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseConv2  (None, None, None,   10368      ['block7a_expand_activation[0][0]\n",
            " D)                             1152)                            ']                               \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormalization  (None, None, None,   4608       ['block7a_dwconv[0][0]']         \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_activation (Activation  (None, None, None,   0          ['block7a_bn[0][0]']             \n",
            " )                              1152)                                                             \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multiply)   (None, None, None,   0           ['block7a_activation[0][0]',     \n",
            "                                1152)                             'block7a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv2D)  (None, None, None,   368640      ['block7a_se_excite[0][0]']      \n",
            "                                320)                                                              \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchNorma  (None, None, None,   1280       ['block7a_project_conv[0][0]']   \n",
            " lization)                      320)                                                              \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, None, None,   409600      ['block7a_project_bn[0][0]']     \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, None, None,   5120        ['top_conv[0][0]']               \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, None, None,   0           ['top_bn[0][0]']                 \n",
            "                                1280)                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,049,571\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,049,571\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here if we notice `Trainable params : 0`, because we haven't trained or changed anything on the patterns or weights, we just did feature extraction, and the layers are unfrozen that's why.\n",
        "\n",
        "We did this by setting `base_model.trainable = False`.\n",
        "\n",
        "Alright that was the `base_model`, let's see the summary of our overall model."
      ],
      "metadata": {
        "id": "DvNfOjbEX4oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the summary of overall model\n",
        "model_0.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2QIDNVtYvBC",
        "outputId": "c98dd52b-8041-4212-b9ab-aeef909b1a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
            "                                                                 \n",
            " global_average_pooling_laye  (None, 1280)             0         \n",
            " r (GlobalAveragePooling2D)                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our overall model has 4 layers, but one of those layers (`efficientnetb0`) has 236 layers.\n",
        "\n",
        "We can also see the output shape of our input_layer is `(None, 224, 224, 3)` but was transformed to `(None, 10)` in the output_layer (shape of our labels), where `None` is the placeholder for the batch size.\n",
        "\n",
        "Notice too, the only trainable params are equal to the params in output_layer, which means we adjusted only the output layer based on our own dataset in this feature extracted model.\n",
        "\n",
        "We are discussing from the last notebook about the feature vectors but haven't really see in practice, how actually it looks like, so let's find."
      ],
      "metadata": {
        "id": "GwX5tAdeYzuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a feature vector from a trained model\n",
        "\n",
        "**What happens with the `tf.keras.layers.GlobalAveragePooling2D()` layer?**\n",
        "\n",
        "The `tf.keras.layers.GlobalAveragePooling2D()` layer transforms a 4D tensor into 2D tensor by averaging the values across the inner-axes.\n",
        "\n",
        "If we see the `model.summary()`, we have 2nd layer as `efficientnetb0` with output shape as `(None, None, None, 1280)` but after applying `tf.keras.layers.GlobalAveragePooling2D` layer, it transforms that into `(None, 1280)`.\n",
        "\n",
        "Let's see an example, how does it do."
      ],
      "metadata": {
        "id": "Q6C-dBpYZ7pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input tensor shape (same number of dimensions as the output of efficientnetb0)\n",
        "input_shape = (1, 4, 4, 3)\n",
        "\n",
        "# Create a random tensor\n",
        "tf.random.set_seed(17)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random Input tensor:\\n {input_tensor}\\n\")\n",
        "\n",
        "# Pass the random tensor through a global average pooling 2d layer\n",
        "global_average_pooling_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooling random tensor:\\n {global_average_pooling_tensor}\\n\")\n",
        "\n",
        "# Check the shapes of the different tensors\n",
        "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"Shape of 2D Global Average Pooled input tensor: {global_average_pooling_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WvqDp86bBY9",
        "outputId": "6a0597d0-bfd6-4be7-e0e6-8fb118c860cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Input tensor:\n",
            " [[[[ 0.01778085  2.3094206  -0.9550922 ]\n",
            "   [-1.7634275   0.4548187  -0.18493938]\n",
            "   [-0.35161677  0.18182382 -0.31690374]\n",
            "   [-0.15134323 -0.07775787  0.17686777]]\n",
            "\n",
            "  [[ 0.21436396  0.1932961   1.4182636 ]\n",
            "   [-0.8006435  -0.70749104 -1.2525052 ]\n",
            "   [ 0.02151339  0.34174567 -1.2530284 ]\n",
            "   [-0.17276597  0.16387203 -0.80704546]]\n",
            "\n",
            "  [[ 0.62522286 -1.5750551  -0.0113454 ]\n",
            "   [-2.2971196   1.3553604  -0.75843495]\n",
            "   [ 0.37949955 -1.5703921  -0.04764017]\n",
            "   [ 0.46110848  1.0848212  -1.0602777 ]]\n",
            "\n",
            "  [[ 0.05737554 -0.88729954  0.8313546 ]\n",
            "   [-0.18021747 -1.0707239  -0.41009685]\n",
            "   [ 1.0844605  -0.04417734 -1.1369785 ]\n",
            "   [-1.3155755   1.670021   -1.1997223 ]]]]\n",
            "\n",
            "2D global average pooling random tensor:\n",
            " [[-0.26071152  0.11389266 -0.43547028]]\n",
            "\n",
            "Shape of input tensor: (1, 4, 4, 3)\n",
            "Shape of 2D Global Average Pooled input tensor: (1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the `tf.keras.layers.GlobalAveragePooling2D()` layer condensed the input tensor from shape `(1, 4, 4, 3)` to `(1, 3)`. It did so by averaging `input_tensor` across the middle two axes.\n",
        "\n",
        "We can replicate this operator using `tf.reduce_mean()` operation and specifying the appropriate axes."
      ],
      "metadata": {
        "id": "pjn25cjFcttZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_mean(input_tensor, axis=[1,2]) # average across the middle axes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_luMAm8dT3d",
        "outputId": "5ea873ef-153d-4a11-9021-5d4e0e263eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.26071152,  0.11389266, -0.43547028]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing this not only makes the output of the base model compatible with the input shape requirement of our output layer(`tf.keras.layers.Dense()`), it also condenses the information found by the base model into a lower dimension **feature vector**.\n",
        "\n",
        "> ðŸ”‘ **Note:** One of the reasons feature extraction transfer learning is named how it is because what often happens is a pretrained model outputs a **feature vector** (a long tensor of numbers, in our case, this is the output of the `tf.keras.layers.GlobalAveragePooling2D()` layer) which can then be used to extract patterns out of.\n",
        "\n",
        "> ðŸ›  **Practice:** Do the same thing with `tf.keras.layers.GlobalMaxPooling2D()`"
      ],
      "metadata": {
        "id": "x-ChVs2ndau8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of transfer learning experiments\n",
        "\n",
        "We've seen the incredible results of transfer learning on 10% of the training data, what about 1% of data ?\n",
        "\n",
        "What kind of results do you think we can get using 100x less data than the original CNN models we built ourselves ?\n",
        "\n",
        "Why don't we answer that question while running the following modelling experiments:\n",
        "1. `model_1`: Use feature extraction transfer leaning on 1% of the training data with data augmentation\n",
        "2. `model_2`: Use feature extraction transfer learning on 10% of the training data with data augmentation\n",
        "3. `model_3`: Use fine-tuning transfer learning on 10% of the training data with data augmentation\n",
        "4. `model_4`: Use fine-tuning transfer learning on 100% of the training data with data augmentation\n",
        "\n",
        "While all of the experiments will be run on different versions of the training data, they will all be evaluated on the same test dataset, this ensures the results of each experiment are as comparable as possible.\n",
        "\n",
        "All the experiments will be done using the `EfficientNetB0` model within the `tf.keras.applications` module.\n",
        "\n",
        "To make sure we're keeping track of our experiments, we'll use our `create_tensorboard_callback()` function to log all of the model training logs.\n",
        "\n",
        "We'll construct each model using the Keras Functional API and instread of implementing data augmentation in the `ImageDataGenerator` class as we have previously, we're going to build it right into the model using `tf.keras.layers.experimental.preprocessing` module.\n",
        "\n",
        "Let's begin by downloading the 1% of training dataset of food vision,"
      ],
      "metadata": {
        "id": "lHDzFJ2ffSyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
        "unzip_data(\"10_food_classes_1_percent.zip\")\n",
        "\n",
        "# Create training and test dirs\n",
        "train_dir_1_percent = \"10_food_classes_1_percent/train/\"\n",
        "test_dir = \"10_food_classes_1_percent/test/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5kdwsJdtnvz",
        "outputId": "892d4c08-f0e7-4b35-a4c5-d88b51fad6ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-19 04:50:38--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.123.128, 142.251.107.128, 74.125.196.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.123.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 133612354 (127M) [application/zip]\n",
            "Saving to: â€˜10_food_classes_1_percent.zipâ€™\n",
            "\n",
            "10_food_classes_1_p 100%[===================>] 127.42M   188MB/s    in 0.7s    \n",
            "\n",
            "2022-12-19 04:50:39 (188 MB/s) - â€˜10_food_classes_1_percent.zipâ€™ saved [133612354/133612354]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Walking through the directory"
      ],
      "metadata": {
        "id": "5q7L4OzduC-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_1_percent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeTavCBCuG_Y",
        "outputId": "ddf1e233-c411-4645-8e1f-3167a3484d21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 files in '10_food_classes_1_percent'\n",
            "There are 10 directories and 0 files in '10_food_classes_1_percent/train'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/chicken_curry'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/pizza'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/ramen'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/grilled_salmon'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/chicken_wings'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/fried_rice'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/sushi'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/hamburger'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/steak'\n",
            "There are 0 directories and 7 files in '10_food_classes_1_percent/train/ice_cream'\n",
            "There are 10 directories and 0 files in '10_food_classes_1_percent/test'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/pizza'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/ramen'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/fried_rice'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/sushi'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/hamburger'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/steak'\n",
            "There are 0 directories and 250 files in '10_food_classes_1_percent/test/ice_cream'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have 7 images per class in training set for directory `10_food_classes_1_percent` and test set are still the same"
      ],
      "metadata": {
        "id": "TITOR3EAuMd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to load our images in as `tf.data.Dataset` objects, to do so, we'll use the `image_dataset_from_directory()` method"
      ],
      "metadata": {
        "id": "inHmS-PeuZjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
        "                                                                           label_mode='categorical',\n",
        "                                                                           batch_size=32,\n",
        "                                                                           image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode='categorical',\n",
        "                                                                image_size=IMG_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "164rbbTGvFCC",
        "outputId": "830b9046-8fc5-41d6-b1a1-e02b0cddc45a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loaded, Time to augment it."
      ],
      "metadata": {
        "id": "a931r2Hzviq8"
      }
    }
  ]
}